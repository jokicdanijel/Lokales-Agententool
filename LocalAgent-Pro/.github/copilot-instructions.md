# LocalAgent-Pro ‚Äî GitHub Copilot Instructions

**Handlungsorientierte Hinweise f√ºr KI-Coding-Agenten** ‚Äî damit du in diesem Repo sofort produktiv bist.

---

## üéØ Projekt-√úbersicht

**LocalAgent-Pro** ist ein Flask-basierter AI-Agent-Server mit OpenWebUI-Integration:

- **Stack:** Python 3.12, Flask, OpenAI SDK, Ollama (LLM)
- **Zweck:** Lokaler Tool-Agent f√ºr Dateisystem-Operationen, Web-Fetching, Shell-Execution
- **Integration:** OpenWebUI (Port 3000), Agent-Server (Port 8001)
- **Sicherheit:** Sandbox-Modus, Domain-Whitelist, Loop-Protection
- **Storage:** SQLite Knowledge DB, Prometheus Monitoring

---

## üìÅ Wichtige Dateien & Einstiegspunkte

```
LocalAgent-Pro/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ openwebui_agent_server.py  # Haupt-Server (Production)
‚îÇ   ‚îú‚îÄ‚îÄ simple_agent.py             # Vereinfachter Demo-Server
‚îÇ   ‚îú‚îÄ‚îÄ tools/                      # Tool-Implementierungen
‚îÇ   ‚îî‚îÄ‚îÄ knowledge_db/               # Wissens-Datenbank
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml                 # Hauptkonfiguration
‚îÇ   ‚îú‚îÄ‚îÄ config_safe.yaml            # Safe-Mode (Loop-Protection)
‚îÇ   ‚îî‚îÄ‚îÄ domain_whitelist.yaml       # Domain Auto-Whitelist
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ restart_server.sh           # Server neu starten
‚îÇ   ‚îú‚îÄ‚îÄ health_check.sh             # Health-Check
‚îÇ   ‚îî‚îÄ‚îÄ cleanup_logs.sh             # Log-Rotation
‚îú‚îÄ‚îÄ logs/                           # Server-Logs
‚îú‚îÄ‚îÄ sandbox/                        # Sandbox-Verzeichnis
‚îî‚îÄ‚îÄ workspace/                      # Test-Dateien
```

**Manifestdateien:**

- `requirements.txt` ‚Äî Python Dependencies
- `config/config.yaml` ‚Äî Runtime-Konfiguration
- `.gitignore` ‚Äî Git-Ausschl√ºsse (inkl. venv)

---

## üöÄ Schnellstart-Befehle

### Server-Management

```bash
# Server starten
bash restart_server.sh

# Server stoppen
bash stop_server.sh

# Health-Check
curl http://127.0.0.1:8001/health | jq '.'

# Logs live anzeigen
tail -f logs/server.log

# Logs analysieren
bash analyze_logs.sh
```

### Testen

```bash
# Tool-Endpunkt testen
curl -X POST http://127.0.0.1:8001/test \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Liste alle Dateien auf"}'

# Chat-Interaktion
./chat-local.sh 'Erstelle Datei test.txt mit Hello World'

# Ollama-Integration testen
python3 test_ollama_integration.py
```

### Entwicklung

```bash
# Virtual Environment aktivieren
source venv/bin/activate

# Dependencies installieren
pip install -r requirements.txt

# Code-Qualit√§t pr√ºfen
python3 -m mypy src/
python3 -m pylint src/
```

---

## ‚öôÔ∏è Konfiguration verstehen

### `config/config.yaml` ‚Äî Haupteinstellungen

```yaml
sandbox: true # Sandbox-Modus (Datei-Isolation)
sandbox_path: "~/localagent_sandbox" # Sandbox-Verzeichnis

allowed_domains: # Domain-Whitelist f√ºr fetch()
  - "github.com"
  - "docs.python.org"

shell_execution:
  enabled: false # Shell-Commands deaktiviert (Sicherheit)
  require_explicit_trigger: true # Nur mit "execute", "run" Trigger

loop_protection: # Loop-Protection (Safe-Mode)
  enabled: true
  max_retries: 1

llm:
  base_url: "http://localhost:11434/v1" # Ollama API
  model: "llama3.1" # LLM-Modell
```

**Wichtig:**

- `sandbox: true` ‚Üí Alle Dateien gehen nach `~/localagent_sandbox/`
- `shell_execution.enabled: false` ‚Üí **Verhindert Loop-Problem** (siehe unten)

---

## üîí Sicherheits-Features (WICHTIG!)

### 1. Loop-Problem (BEHOBEN)

**Problem:** Fr√ºher interpretierte der Server normale Texteingaben als Shell-Commands ‚Üí Endlosschleifen.

**L√∂sung:**

- `config_safe.yaml` verwenden (bereits aktiv)
- `shell_execution.enabled: false` (Standard)
- Loop-Protection mit `max_retries: 1`

**Dokumentation:** Siehe `LOOP_PROBLEM_ANALYSIS.md`, `LOOP_FIX_SUMMARY.md`

### 2. Sandbox-Modus

Alle Datei-Operationen werden in `~/localagent_sandbox/` umgeleitet:

```python
# User fragt: "Erstelle /etc/passwd"
# Tats√§chlicher Pfad: ~/localagent_sandbox/etc/passwd ‚úÖ
```

### 3. Domain-Whitelist

Nur erlaubte Domains f√ºr `fetch()`:

```python
# ‚úÖ fetch("https://github.com/...")  ‚Üí Erlaubt
# ‚ùå fetch("https://evil.com/...")    ‚Üí Blockiert
```

---

## üõ†Ô∏è Code-√Ñnderungen: Best Practices

### Pattern: Tool-Implementierung

Neue Tools in `src/tools/` hinzuf√ºgen:

```python
# src/tools/new_tool.py
def my_new_tool(param: str) -> str:
    """Tool-Beschreibung f√ºr LLM."""
    # Implementierung
    return result

# In openwebui_agent_server.py registrieren:
TOOLS["my_new_tool"] = my_new_tool
```

### Pattern: Config-√Ñnderungen

1. **Backup erstellen:** `cp config/config.yaml config/config_backup.yaml`
2. **√Ñnderungen vornehmen**
3. **Server neu starten:** `bash restart_server.sh`
4. **Testen:** `curl http://127.0.0.1:8001/health`

### Anti-Pattern: Direkter DB-Zugriff

‚ùå **Nicht tun:**

```python
conn = sqlite3.connect('knowledge.db')
conn.execute("DROP TABLE ...") # Destruktiv!
```

‚úÖ **Stattdessen:**

```python
from src.knowledge_db.manager import KnowledgeDB
kb = KnowledgeDB()
kb.safe_operation()  # Nutze API
```

---

## üîç Debugging & Troubleshooting

### H√§ufige Probleme

**Problem:** Server startet nicht

```bash
# Pr√ºfe Port
sudo lsof -i :8001

# Pr√ºfe Logs
tail -50 logs/server.log

# Pr√ºfe Config-Syntax
python3 -c "import yaml; yaml.safe_load(open('config/config.yaml'))"
```

**Problem:** "Exit Code: 2" Fehler in Logs
‚Üí **Loop-Problem aktiv!** Siehe `LOOP_FIX_QUICKSTART.md`

**Problem:** Ollama nicht erreichbar

```bash
# Ollama-Status pr√ºfen
curl http://localhost:11434/api/tags

# Ollama neu starten
pkill ollama && ollama serve
```

---

## üìñ Dokumentations-Hierarchie

### F√ºr Quick-Start:

1. `QUICK_START.md` ‚Äî Erste Schritte
2. `SOFORT_START.md` ‚Äî Installations-Guide
3. `README.md` ‚Äî Projekt-√úbersicht

### F√ºr Entwicklung:

1. `COMPLETE_GUIDE.md` ‚Äî Vollst√§ndige Referenz
2. `ENDPOINT_CHEATSHEET.md` ‚Äî API-Endpunkte
3. `LOGGING_GUIDE.md` ‚Äî Logging-Konfiguration

### F√ºr Probleme:

1. `LOOP_FIX_QUICKSTART.md` ‚Äî Loop-Problem 2-Min-Fix
2. `LOOP_PROBLEM_ANALYSIS.md` ‚Äî Technische Analyse
3. `SECURITY_UPDATE.md` ‚Äî Sicherheits-Updates

### F√ºr Integration:

1. `OPENWEBUI_INTEGRATION.md` ‚Äî OpenWebUI Setup
2. `PROMETHEUS_INTEGRATION.md` ‚Äî Monitoring
3. `ELION_INTEGRATION.md` ‚Äî Elion-CLI

---

## üí° Typische Agent-Aufgaben

### Datei-Operationen

```bash
./chat-local.sh 'Liste alle Dateien im workspace auf'
./chat-local.sh 'Lies config/config.yaml'
./chat-local.sh 'Erstelle test.txt mit "Hello LocalAgent"'
```

### Code-Analyse

```bash
./chat-local.sh 'Zeige mir alle Python-Dateien in src/'
./chat-local.sh 'Erkl√§re die Tool-Architektur'
./chat-local.sh 'Welche Dependencies werden verwendet?'
```

### Troubleshooting

```bash
./chat-local.sh 'Warum startet der Server nicht?'
./chat-local.sh 'Analysiere die letzten 50 Log-Eintr√§ge'
./chat-local.sh 'Pr√ºfe ob Ollama erreichbar ist'
```

---

## üß™ Testing-Checkliste

Vor jedem Commit:

- [ ] `bash restart_server.sh` erfolgreich
- [ ] Health-Check: `curl http://127.0.0.1:8001/health` ‚Üí `status: ok`
- [ ] Keine Errors in `logs/server.log`
- [ ] Loop-Test: Sende problematischen Input (`/mnt/data/test.py`) ‚Üí Keine Loops
- [ ] Sandbox-Test: Datei erstellen ‚Üí Landet in `~/localagent_sandbox/`

---

## üö® Kritische Regeln

1. **NIE `venv/` committen** ‚Äî Ist bereits in `.gitignore`
2. **NIE `shell_execution.enabled: true`** ohne Loop-Protection
3. **IMMER** Config-Backups vor √Ñnderungen
4. **IMMER** Safe-Mode testen nach Code-√Ñnderungen
5. **NIE** destruktive DB-Operationen ohne Migration

---

## üìä Monitoring & Metrics

### Health-Check Response

```json
{
  "status": "ok",
  "sandbox": true,
  "model": "llama3.1",
  "allowed_domains": ["github.com", "..."],
  "server_time": 1732000000
}
```

### Log-Analyse

```bash
# Fehler z√§hlen
grep -c "ERROR" logs/server.log

# Loop-Erkennungen
grep "Loop" logs/server.log

# Shell-Executions
grep "Shell-Kommando" logs/server.log
```

---

## üéØ N√§chste Schritte f√ºr Agenten

1. **Erste Orientierung:** Lies `README.md` und `QUICK_START.md`
2. **Server starten:** `bash restart_server.sh`
3. **Test ausf√ºhren:** `./chat-local.sh 'Hallo LocalAgent!'`
4. **Config verstehen:** √ñffne `config/config.yaml`
5. **Code erkunden:** Starte in `src/openwebui_agent_server.py`

---

**Status:** ‚úÖ Production-Ready | **Letzte Aktualisierung:** 19.11.2025  
**F√ºr Fragen:** Siehe `COMPLETE_GUIDE.md` oder f√ºhre `./chat-local.sh` mit deiner Frage aus.
